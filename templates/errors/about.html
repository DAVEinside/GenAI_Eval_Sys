{% extends "base.html" %}

{% block title %}About - GenAI Evaluation System{% endblock %}

{% block content %}
<div class="row justify-content-center">
    <div class="col-lg-10">
        <h1 class="mb-4">About the Generative AI Content Evaluation System</h1>
        
        <div class="card mb-4">
            <div class="card-body">
                <h2 class="mb-3">Project Overview</h2>
                <p class="lead">
                    The Generative AI Content Evaluation System is a comprehensive platform designed to systematically evaluate
                    AI-generated content against human expert benchmarks across multiple domains.
                </p>
                <p>
                    As generative AI systems become increasingly capable of producing content across various domains,
                    there is a critical need for robust, scalable evaluation methods that can reliably assess the quality
                    of this content and identify areas for improvement. Our system addresses this need through a
                    combination of expert human evaluation, quality control processes, and advanced analytics.
                </p>
            </div>
        </div>
        
        <div class="row mb-4">
            <div class="col-md-4">
                <div class="card h-100">
                    <div class="card-body">
                        <h3 class="card-title">Systematic Evaluation</h3>
                        <p>
                            Our platform implements a structured approach to evaluate AI-generated content
                            using consistent criteria and methodologies across different content types.
                            This enables meaningful comparisons and reliable quality assessments.
                        </p>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card h-100">
                    <div class="card-body">
                        <h3 class="card-title">Expert Interfaces</h3>
                        <p>
                            We've created specialized interfaces for domain experts to provide detailed feedback
                            on model outputs, allowing for nuanced evaluation that captures the complexity
                            of different content domains and quality dimensions.
                        </p>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card h-100">
                    <div class="card-body">
                        <h3 class="card-title">Quality Control</h3>
                        <p>
                            Robust quality control mechanisms ensure consistent and reliable human evaluations,
                            addressing issues such as evaluator bias, inconsistency, and quality variability
                            to provide dependable feedback.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="card mb-4">
            <div class="card-body">
                <h2 class="mb-3">Key Features</h2>
                <ul class="list-group list-group-flush">
                    <li class="list-group-item">
                        <strong>Multi-domain Evaluation:</strong> Supports evaluation across creative writing, technical documentation, 
                        marketing copy, news articles, academic papers, and social media content domains.
                    </li>
                    <li class="list-group-item">
                        <strong>Comprehensive Criteria:</strong> Evaluates content on multiple dimensions including accuracy, 
                        coherence, relevance, creativity, completeness, and language quality.
                    </li>
                    <li class="list-group-item">
                        <strong>Expert Portal:</strong> Specialized interface for domain experts to provide detailed 
                        evaluations based on their expertise.
                    </li>
                    <li class="list-group-item">
                        <strong>Quality Assurance:</strong> Built-in quality control mechanisms including attention checks, 
                        time tracking, and evaluator consistency analysis.
                    </li>
                    <li class="list-group-item">
                        <strong>Analytics Dashboard:</strong> Comprehensive analytics to identify model strengths and weaknesses, 
                        compare different models, and track improvement over time.
                    </li>
                    <li class="list-group-item">
                        <strong>Improvement Recommendations:</strong> Actionable suggestions for model improvements based on 
                        evaluation data and human-AI gap analysis.
                    </li>
                </ul>
            </div>
        </div>
        
        <div class="card mb-4">
            <div class="card-body">
                <h2 class="mb-3">Results</h2>
                <p>
                    Using this system, we've been able to achieve significant improvements in AI model alignment with human preferences:
                </p>
                <div class="row">
                    <div class="col-md-6">
                        <div class="card bg-light">
                            <div class="card-body text-center">
                                <h3 class="display-4 text-primary">30%</h3>
                                <p class="lead">Better alignment with human preferences</p>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="card bg-light">
                            <div class="card-body text-center">
                                <h3 class="display-4 text-primary">6</h3>
                                <p class="lead">Content domains evaluated</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <div class="card-body">
                <h2 class="mb-3">Team</h2>
                <p>
                    The Generative AI Content Evaluation System was developed by a multidisciplinary team with expertise in:
                </p>
                <ul>
                    <li>Artificial Intelligence and Machine Learning</li>
                    <li>Human-Computer Interaction</li>
                    <li>Content Quality Evaluation</li>
                    <li>Natural Language Processing</li>
                    <li>Software Engineering and Web Development</li>
                </ul>
                <p>
                    Our team continues to enhance the system's capabilities, refine evaluation methodologies, 
                    and expand its domain coverage to provide even more comprehensive assessment of AI-generated content.
                </p>
            </div>
        </div>
    </div>
</div>
{% endblock %}